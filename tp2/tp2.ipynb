{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trabalho Prático 02 - Realidade Aumentada\n",
    "\n",
    "- Giovanna Louzi Bellonia - 2017086015\n",
    "- Thiago Martin Poppe - 2017014324\n",
    "\n",
    "\n",
    "- __Obs.:__ Por problemas graves com a biblioteca GLUT, não conseguimos rodar o TP usando ela... Por isso, optamos por utilizar a biblioteca GLFW com versão 1.8.0. Para baixar via anaconda, basta rodar o comando conda install -c conda-forge glfw ou pelo pip usando o comando pip install glfw. Caso não consiga rodar o código por completo, enviaremos uma imagem juntamente com o notebook para mostrar o resultado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.8.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import glfw\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from OpenGL.GL import *\n",
    "from OpenGL.GLU import *\n",
    "from OpenGL.GLUT import *\n",
    "\n",
    "from ObjLoader import OBJ\n",
    "\n",
    "glfw.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lendo o vídeo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Video ended ***\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture('entrada.avi')\n",
    "frames = []\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if ret == False:\n",
    "        print('*** Video ended ***')\n",
    "        break\n",
    "        \n",
    "    frames.append(frame)\n",
    "    \n",
    "frames = np.array(frames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Função homography\n",
    "- Função criada para estimar a matriz de homografia utilizando a função findHomography com o método RANSAC para filtrar erros grosseiros e a função warpPerspective para aplicar tal matriz na imagem.\n",
    "- Irá retornar o resultado binarizado para realizarmos posteriormente um template matching mais preciso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def homography(img, src, target):\n",
    "    \"\"\"\n",
    "        Estima e aplica a matriz de homografia em um conjunto de pontos\n",
    "        \n",
    "        Parâmetros\n",
    "        ----------\n",
    "        img : numpy.ndarray\n",
    "            Imagem de onde os pontos foram extraídos\n",
    "            \n",
    "        src : numpy.ndarray\n",
    "            Pontos de origem (da imagem)\n",
    "            \n",
    "        target : numpy.ndarray\n",
    "            Pontos do alvo\n",
    "            \n",
    "        Retorno\n",
    "        -------\n",
    "        numpy.ndarray\n",
    "            Retorna aquela parte da imagem binarizada e com a homografia aplicada\n",
    "    \"\"\"\n",
    "    \n",
    "    # Obtendo os pontos no alvo e estimando a matriz de homografia usando RANSAC\n",
    "    height, width = target.shape\n",
    "    dst = np.float32([[0,0], [0, height], [width, height], [width, 0]])\n",
    "    M = cv2.findHomography(src, dst, cv2.RANSAC)[0]\n",
    "    \n",
    "    # Aplicando o warpPerspective e binarizando a imagem\n",
    "    result = cv2.warpPerspective(img, M, (width, height))\n",
    "    result[result < 80] = 0\n",
    "    result[result >= 80] = 255\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Função get_targets\n",
    "- Função auxiliar usada para ler o arquivo que contêm o alvo, retornando o mesmo rotacionado em 0º, 90º, 180º e 270º respectivamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_targets(filename):\n",
    "    \"\"\"\n",
    "        Retorna o alvo rotacionado em 0º, 90º, 180º e 270º\n",
    "        \n",
    "        Parâmetros\n",
    "        ----------\n",
    "        filename : str\n",
    "            Nome do arquivo, .jpg por exemplo, do alvo\n",
    "            \n",
    "        Retorno\n",
    "        -------\n",
    "        list\n",
    "            Lista contendo o alvo rotacionado em 0º, 90º, 180º e 270º (nessa ordem)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Lendo o alvo, convertendo para escalas de cinza e binarizando\n",
    "    target = cv2.imread(filename)\n",
    "    target = cv2.cvtColor(target, cv2.COLOR_BGR2GRAY)\n",
    "    target[target < 25] = 0\n",
    "    target[target >= 25] = 255\n",
    "    \n",
    "    targets_list = []\n",
    "    \n",
    "    # Rotacionando o alvo em cada um dos ângulos e salvando em uma lista\n",
    "    for angle in [0, 90, 180, 270]:\n",
    "        M = cv2.getRotationMatrix2D((target.shape[1]/2, target.shape[0]/2), angle, 1)\n",
    "        targets_list.append(cv2.warpAffine(target, M, (target.shape[0], target.shape[1])))\n",
    "                            \n",
    "    return targets_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Função similarity_func\n",
    "\n",
    "- Função criada para retornar o quão similar duas imagens são.\n",
    "- Fizemos um cálculo de diferença média absoluta dos pixels para tal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity_func(img1, img2):\n",
    "    \"\"\"\n",
    "        Função de similaridade usando a diferença média dos pixels\n",
    "        \n",
    "        Parâmetros\n",
    "        ----------\n",
    "        img1 : numpy.ndarray\n",
    "            Imagem 1 a ser comparada\n",
    "            \n",
    "        img2 : numpy.ndarray\n",
    "            Imagem 2 a ser comparada\n",
    "            \n",
    "        Retorno\n",
    "        -------\n",
    "            Retorna o valor da diferença média dos pixels\n",
    "    \"\"\"\n",
    "    \n",
    "    return np.sum(np.abs(img1 - img2)) / (img1.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Função template_matching\n",
    "- Essa função cumpre o papel de: para cada imagem do alvo rotacionado, verificar o quão similar ela é com a imagem obtida no passo da homografia. Salvando o índice da imagem que possui o menor valor retornado pela função similarity_func, em outras palavras, a mais similar.\n",
    "- Caso essa imagem não possua valor de similaridade menor do que a tolerância definida, não aceitamos e retornamos -1. Caso contrário, retornamos o índice encontrado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def template_matching(img, targets, sim_func, tol=25):\n",
    "    \"\"\"\n",
    "        Função que realiza o casamento de template\n",
    "        \n",
    "        Parâmetros\n",
    "        ----------\n",
    "        img : numpy.ndarray\n",
    "            Imagem que se quer casar\n",
    "            \n",
    "        targets : numpy.ndarray list\n",
    "            Lista de alvos que iremos casar\n",
    "            \n",
    "        simFunc : function\n",
    "            Função de similaridade que aceita dois numpy.ndarray,\n",
    "            realiza os cálculos e retorna um número\n",
    "            \n",
    "        tol : float, opcional\n",
    "            Tolerância para ser um casamento válido (por padrão é 25)\n",
    "            \n",
    "        Retorno\n",
    "        -------\n",
    "        int\n",
    "            Caso o valor de similaridade esteja abaixo da tolerância,\n",
    "            retornamos o índice do alvo que resultou em um casamento\n",
    "            bem-sucedido (seguindo a mesma ordem dos ângulos).\n",
    "            Senão, retornamos -1.\n",
    "    \"\"\"\n",
    "    \n",
    "    min_similarity = sim_func(img, targets[0])\n",
    "    min_pos = 0\n",
    "    \n",
    "    # Caminhando por cada alvo, comparando o valor de similaridade do atual e \n",
    "    # atualizando, caso necessário, as variáveis\n",
    "    for i in range(1, len(targets)):\n",
    "        current = sim_func(img, targets[i])\n",
    "        if current < min_similarity:\n",
    "            min_similarity = current\n",
    "            min_pos = i\n",
    "    \n",
    "    return min_pos if min_similarity <= tol else -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Função seek_targets\n",
    "\n",
    "- Essa função cumpre o papel de retornar os pontos dos alvos na cena. Usaremos a função findContours da OpenCV para tal, juntamente com a homography e template_matching para realizar o casamento de padrões.\n",
    "- Para cada contorno encontrado, aproximaremos o mesmo por um polígono e, se esse tiver um tamanho igual a 4 faremos a homografia seguida do template matching para ele e, se retornar verdadeiro, guardaremos seus pontos no vetor \"pts\" e a posição em que se encontra em \"pos\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seek_targets(img, targets):\n",
    "    \"\"\"\n",
    "        Função que retorna os pontos dos alvos na cena\n",
    "        \n",
    "        Parâmetros:\n",
    "        ----------\n",
    "        img : np.ndarray\n",
    "            Imagem a ser analisada\n",
    "            \n",
    "        targets : list of np.ndarray\n",
    "            Alvos no qual iremos realizar o template matching\n",
    "            \n",
    "        Retorno:\n",
    "        -------\n",
    "        list of np.ndarray and int list\n",
    "            A função irá retornar os pontos dos alvos encontrados na cena e com qual alvo rotacionado o casamento\n",
    "            foi bem sucedido\n",
    "    \"\"\"\n",
    "\n",
    "    pts = []\n",
    "    pos = []\n",
    "\n",
    "    # Convertendo a imagem para tons de cinza\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.bilateralFilter(gray, 11, 17, 17)\n",
    "    \n",
    "    # Detectando bordas com Canny e usando a findContours\n",
    "    canny = cv2.Canny(gray, 100, 200)\n",
    "    contours, _ = cv2.findContours(canny, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    for c in contours:\n",
    "        # Aproximando o contorno via um polígono \n",
    "        peri = cv2.arcLength(c, True)\n",
    "        approx = cv2.approxPolyDP(c, 0.02 * peri, True)\n",
    "        \n",
    "        # Caso esse polígono possua 4 pontos adicionamos ele na nossa lista se a homografia retornar como correto\n",
    "        if len(approx) == 4:\n",
    "            result = homography(np.float32(gray), np.float32(approx), targets[0])\n",
    "            match = template_matching(result, targets, similarity_func, 30)\n",
    "            \n",
    "            if  match != -1:\n",
    "                pos.append(match)\n",
    "                pts.append(approx)\n",
    "                \n",
    "        # Caso encontremos 3 alvos, podemos parar o loop\n",
    "        if len(pts) == 3:\n",
    "            break\n",
    "    \n",
    "    return pts, pos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Função get_object_pts\n",
    "\n",
    "- Função auxiliar que dado uma pose do alvo, iremos retornar o valor correto dos pontos do mesmo para a função solvePnP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_object_pts(pos):\n",
    "    \"\"\"\n",
    "        Função que retorna o valor correto dos pontos do objeto para a função solvePnP\n",
    "        \n",
    "        Parâmetros:\n",
    "        ----------\n",
    "        int\n",
    "            Valor que indica com qual alvo o casamento foi bem sucedido (0 -> 0º, 1 -> 90º, 2 -> 180º ou 3 -> 270º)\n",
    "\n",
    "        Retorno:\n",
    "        -------\n",
    "        np.ndarray\n",
    "            Vetor de pontos do objeto na orientação correta\n",
    "    \"\"\"\n",
    "    \n",
    "    if pos == 0:\n",
    "        return np.float32([[1,1,1], [1,-1,1], [-1,-1,1], [-1,1,1]])\n",
    "    if pos == 1:\n",
    "        return np.float32([[-1,-1,1], [-1,1,1], [1,1,1], [1,-1,1]])\n",
    "    if pos == 2:\n",
    "        return np.float32([[1,-1,1], [-1,-1,1], [-1,1,1], [1,1,1]])\n",
    "    if pos == 3:\n",
    "        return np.float32([[-1,1,1], [1,1,1], [1,-1,1], [-1,-1,1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Função loadBackgroundTexture\n",
    "\n",
    "- Função que utiliza OpenGL para carregar a textura da cena como background, retornando o 'id' do buffer gerado pela OpenGL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadBackgroundTexture(img):\n",
    "    '''\n",
    "        Função que carrega a textura do fundo da cena para a OpenGL\n",
    "        \n",
    "        Parâmetros:\n",
    "        ----------\n",
    "        img : numpy.ndarray\n",
    "            Imagem a ser usada como textura\n",
    "            \n",
    "        Retorno:\n",
    "        -------\n",
    "        int\n",
    "            Id da textura criado pela OpenGL\n",
    "    '''\n",
    "    \n",
    "    # Criando um id para a textura e habilitando\n",
    "    background_id = glGenTextures(1)\n",
    "    glBindTexture(GL_TEXTURE_2D, background_id)\n",
    "    \n",
    "    # Convertendo a imagem de BGR para RGB e realizando um 'flip'\n",
    "    background = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    background = cv2.flip(background, 0)\n",
    "    \n",
    "    # Convertendo a imagem para uma string\n",
    "    height, width, channels = background.shape\n",
    "    background = np.fromstring(background.tostring(), dtype=background.dtype, count = height * width * channels)    \n",
    "    background.shape = (height, width, channels)\n",
    "\n",
    "    # Criando a textura na OpenGL\n",
    "    glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER, GL_LINEAR)\n",
    "    glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_LINEAR)\n",
    "    glTexImage2D(GL_TEXTURE_2D, 0, GL_RGB, width, height, 0, GL_RGB, GL_UNSIGNED_BYTE, background)\n",
    "    \n",
    "    # Retornando o id\n",
    "    return background_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Função showBackground\n",
    "\n",
    "- Função que utiliza OpenGL para gerar o fundo da nossa cena"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showBackground(img):\n",
    "    \"\"\"\n",
    "        Função que desenha o fundo da cena.\n",
    "        \n",
    "        Parâmetros:\n",
    "        ----------\n",
    "        img : np.ndarray\n",
    "            Imagem a ser colocada como textura\n",
    "    \"\"\"\n",
    "    \n",
    "    # Lendo a textura\n",
    "    textureId = loadBackgroundTexture(img)\n",
    "    \n",
    "    # Desabilitando o glDepthMask\n",
    "    glDepthMask(GL_FALSE)\n",
    "    \n",
    "    # Definindo a projeção como ortográfica\n",
    "    glMatrixMode(GL_PROJECTION)\n",
    "    glPushMatrix()\n",
    "    glLoadIdentity()\n",
    "    gluOrtho2D(0, width, 0, height)\n",
    "    \n",
    "    # Habilitando a textura\n",
    "    glEnable(GL_TEXTURE_2D)\n",
    "    glBindTexture(GL_TEXTURE_2D, textureId)\n",
    "    glMatrixMode(GL_MODELVIEW)\n",
    "    glPushMatrix()\n",
    "    \n",
    "    # Desenhando um quadrilátero do tamanho da tela com a textura\n",
    "    glBegin(GL_QUADS)\n",
    "    glTexCoord2f(0, 0); glVertex2f(0, 0)\n",
    "    glTexCoord2f(1, 0); glVertex2f(width, 0)\n",
    "    glTexCoord2f(1, 1); glVertex2f(width, height)\n",
    "    glTexCoord2f(0, 1); glVertex2f(0, height)\n",
    "    glEnd()\n",
    "    \n",
    "    glPopMatrix()\n",
    "    glMatrixMode(GL_PROJECTION)\n",
    "    glPopMatrix()\n",
    "    glMatrixMode(GL_MODELVIEW)\n",
    "    \n",
    "    # Desabilitando a textura e chamando glFlush\n",
    "    # glDepthMask -> faz com que o fundo não fique na frente do Pikachu\n",
    "    glBindTexture(GL_TEXTURE_2D, 0)\n",
    "    glDepthMask(GL_TRUE)\n",
    "    glFlush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Função initOpenGL\n",
    "\n",
    "- Função auxiliar para iniciar a OpenGL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initOpenGL():\n",
    "    \"\"\"\n",
    "        Função que inicializa a OpenGL\n",
    "        \n",
    "        Retorno:\n",
    "        -------\n",
    "        Retorna o .obj carregado na memória\n",
    "    \"\"\"\n",
    "    \n",
    "    # Habilitando o uso de texturas e de profundidade\n",
    "    glEnable(GL_TEXTURE_2D)\n",
    "    glEnable(GL_DEPTH_TEST)\n",
    "    \n",
    "    # Carregando o objeto Pikachu na memória\n",
    "    obj = OBJ('Pikachu.obj', swapyz=True)\n",
    "    \n",
    "    # Definindo o modo de projeção da cena\n",
    "    glMatrixMode(GL_PROJECTION)\n",
    "    glLoadIdentity()\n",
    "    \n",
    "    # Usando os parâmetros intrínsecos da câmera para calcular o fovy e aspect ratio\n",
    "    fx = cameraParams['fc'][0]\n",
    "    fy = cameraParams['fc'][1]\n",
    "    fovy = 2 * np.arctan(0.5 * height / fy)*180 / np.pi\n",
    "    aspect = (width*fy) / (height*fx)\n",
    "    gluPerspective(fovy, aspect, 0.1, 100.0)\n",
    "    \n",
    "    # Definindo a cor de limpeza do fundo\n",
    "    glClearColor(0.2, 0.2, 0.2, 0.0)\n",
    "    \n",
    "    return obj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Função showObject\n",
    "\n",
    "- Função que cumpre o papel de exibir o objeto (Pikachu) na cena fazendo uso da OpenGL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showObject(pts, pos):\n",
    "    \"\"\"\n",
    "        Função que renderiza o objeto na cena\n",
    "        \n",
    "        Parâmetros:\n",
    "        ----------\n",
    "        pts : np.ndarray\n",
    "            Pontos do alvo na cena\n",
    "            \n",
    "        pos : int\n",
    "            Inteiro que indica com qual alvo estamos casando\n",
    "    \"\"\"\n",
    "    \n",
    "    dst = get_object_pts(pos)\n",
    "    _, rvec, tvec = cv2.solvePnP(dst, np.float32(pts), intMatrix, cameraParams['kc'])\n",
    "    rotm = cv2.Rodrigues(rvec)[0]\n",
    "\n",
    "    m = np.array([\n",
    "        [rotm[0][0], rotm[0][1], rotm[0][2], tvec[0]],\n",
    "        [rotm[1][0], rotm[1][1], rotm[1][2], -tvec[1]],\n",
    "        [rotm[2][0], rotm[2][1], rotm[2][2], -tvec[2]],\n",
    "        [0.0, 0.0, 0.0, 1.0]\n",
    "    ])\n",
    "\n",
    "#     m = m * np.array([[ 1.0,  1.0,  1.0,  1.0],\n",
    "#                       [-1.0, -1.0, -1.0, -1.0],\n",
    "#                       [-1.0, -1.0, -1.0, -1.0],\n",
    "#                       [ 1.0,  1.0,  1.0,  1.0]])\n",
    "\n",
    "    m = np.transpose(m)\n",
    "    \n",
    "    glMatrixMode(GL_MODELVIEW)\n",
    "    glLoadIdentity()\n",
    "    glPushMatrix()\n",
    "    glLoadMatrixf(m)\n",
    "    glCallList(obj.gl_list)\n",
    "    glPopMatrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Função draw\n",
    "\n",
    "- Função que irá representar o nosso loop principal na OpenGL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw():\n",
    "    \"\"\"\n",
    "        Função que irá representar nosso main loop na OpenGL\n",
    "    \"\"\"\n",
    "   # Limpando os buffers\n",
    "    glClear(GL_COLOR_BUFFER_BIT | GL_DEPTH_BUFFER_BIT)\n",
    "    \n",
    "    # Desenhando o fundo\n",
    "    showBackground(frames[i])\n",
    "    \n",
    "    # Desenhando os objetos nos alvos\n",
    "    pts, pos = seek_targets(frames[i], targets)\n",
    "    for j in range(len(pts)):\n",
    "        showObject(pts[j], pos[j])\n",
    "    \n",
    "    i += 1\n",
    "    \n",
    "    # Trocando de buffer para exibir na tela\n",
    "    glutSwapBuffers()\n",
    "    \n",
    "    # Caso tenhamos lido todos os frames podemos retornar\n",
    "    if i > len(frames):\n",
    "        return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definindo os parâmetros intrínsecos da câmera\n",
    "\n",
    "- Os valores da distância focal, centro óptico e coeficientes de distorção da câmera foram obtidos atráves da calibração pelo MATLAB utilizando o toolbox_calib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definindo os parâmetros intrínsecos da câmera através da calibração pelo MATLAB\n",
    "cameraParams = {\n",
    "    'fc': [536.19341, 536.14756],\n",
    "    'cc': [317.64968, 233.56773],\n",
    "    'kc': np.array([0.07459, -0.15101, -0.00544, 0.00111, 0.00000])\n",
    "}\n",
    "\n",
    "# Definindo a matriz de parâmetros intrínsecos\n",
    "intMatrix = np.array([\n",
    "    [cameraParams['fc'][0], 0.0, cameraParams['cc'][0]],\n",
    "    [0.0, cameraParams['fc'][1], cameraParams['cc'][1]],\n",
    "    [0.0, 0.0, 1.0]\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Renderizando os objetos com a OpenGL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\ICV\\lib\\site-packages\\ipykernel_launcher.py:26: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n"
     ]
    }
   ],
   "source": [
    "# Definindo o tamanho da nossa janela\n",
    "width, height = 640, 480\n",
    "\n",
    "# Iniciando o glfw\n",
    "if not glfw.init():\n",
    "    print('*** ERRO AO INICIAR O GLFW ***')\n",
    "    \n",
    "# Criando uma janela\n",
    "window = glfw.create_window(width, height, 'TP2', None, None)\n",
    "glfw.make_context_current(window)\n",
    "\n",
    "# Carregando os alvos\n",
    "targets = get_targets('alvo.jpg')\n",
    "\n",
    "# Iniciando a OpenGL e carregando o objeto na memória\n",
    "obj = initOpenGL()\n",
    "\n",
    "i = 0\n",
    "while not glfw.window_should_close(window):\n",
    "    glfw.poll_events()\n",
    "    \n",
    "    # Limpando os buffers\n",
    "    glClear(GL_COLOR_BUFFER_BIT | GL_DEPTH_BUFFER_BIT)\n",
    "    \n",
    "    # Desenhando o fundo\n",
    "    showBackground(frames[i])\n",
    "    \n",
    "    # Desenhando os objetos nos alvos\n",
    "    pts, pos = seek_targets(frames[i], targets)\n",
    "    for j in range(len(pts)):\n",
    "        showObject(pts[j], pos[j])\n",
    "    \n",
    "    i += 1\n",
    "    \n",
    "    # Caso tenhamos lido todos os frames podemos retornar\n",
    "    if i >= len(frames):\n",
    "        break\n",
    "    \n",
    "    glfw.swap_buffers(window)\n",
    "    \n",
    "# Encerrando o GLFW\n",
    "glfw.terminate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusões\n",
    "\n",
    "- Observamos que a orientação do alvo da esquerda foi estimada de maneira errada. Como no TP1 ela foi estimada de forma certa usando o nosso método de captura dos pontos dos alvos no sentido anti-horário, acreditamos que a função findContours da OpenCV retorna os pontos em uma ordem diferente da que estavamos esperando. Resultando assim, em um casamento errado ao passarmos esses pontos pelo nosso pipeline. Por questões de tempo, não conseguimos resolver esses pequenos detalhes de implementação, porém, acreditamos que o erro está na ordem em que os pontos foram passados para as funções da OpenCV.\n",
    "\n",
    "\n",
    "- Caso não consiga rodar o código por algum motivo, deixaremos prints de vários frames mostrando os resultados!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
