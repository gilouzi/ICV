{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import glfw\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from OpenGL.GL import *\n",
    "from OpenGL.GLU import *\n",
    "from OpenGL.GLUT import *\n",
    "\n",
    "from ObjLoader import OBJ\n",
    "from OpenGLMiscFunctions import loadBackgroundTexture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lendo o vídeo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture('entrada.avi')\n",
    "frames = []\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if ret == False:\n",
    "        print('*** Video ended ***')\n",
    "        break\n",
    "        \n",
    "    frames.append(frame)\n",
    "    \n",
    "frames = np.array(frames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Função show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A função *show* foi definida para que pudessemos ver as imagens na célula do notebook sem precisarmos abrir a janela extra do OpenCV, facilitando os testes e análises."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show(img):\n",
    "    \"\"\"\n",
    "        Exibe uma imagem, na própria célula, usando matplotlib\n",
    "        \n",
    "        Parâmetros:\n",
    "        ----------\n",
    "        img : numpy.ndarray\n",
    "            Imagem a ser exibida\n",
    "    \"\"\"\n",
    "    \n",
    "    fig, ax = plt.subplots(1, 1, figsize=(10, 10))\n",
    "    ax.imshow(img, cmap=plt.cm.gray)\n",
    "    ax.set_axis_off()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Função homography\n",
    "- Função criada para estimar a matriz de homografia utilizando a função findHomography com o método RANSAC para filtrar erros grosseiros e a função warpPerspective para aplicar tal matriz na imagem.\n",
    "- Irá retornar o resultado binarizado para realizarmos posteriormente um template matching mais preciso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def homography(img, src, target):\n",
    "    \"\"\"\n",
    "        Estima e aplica a matriz de homografia em um conjunto de pontos\n",
    "        \n",
    "        Parâmetros\n",
    "        ----------\n",
    "        img : numpy.ndarray\n",
    "            Imagem de onde os pontos foram extraídos\n",
    "            \n",
    "        src : numpy.ndarray\n",
    "            Pontos de origem (da imagem)\n",
    "            \n",
    "        target : numpy.ndarray\n",
    "            Pontos do alvo\n",
    "            \n",
    "        Retorno\n",
    "        -------\n",
    "        numpy.ndarray\n",
    "            Retorna aquela parte da imagem binarizada e com a homografia aplicada\n",
    "    \"\"\"\n",
    "    \n",
    "    # Obtendo os pontos no alvo e estimando a matriz de homografia usando RANSAC\n",
    "    height, width = target.shape\n",
    "    dst = np.float32([[0,0], [0, height], [width, height], [width, 0]])\n",
    "    M = cv2.findHomography(src, dst, cv2.RANSAC)[0]\n",
    "    \n",
    "    # Aplicando o warpPerspective e binarizando a imagem\n",
    "    result = cv2.warpPerspective(img, M, (width, height))\n",
    "    result[result < 80] = 0\n",
    "    result[result >= 80] = 255\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Função get_targets\n",
    "- Função auxiliar usada para ler o arquivo que contêm o alvo, retornando o mesmo rotacionado em 0º, 90º, 180º e 270º respectivamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_targets(filename):\n",
    "    \"\"\"\n",
    "        Retorna o alvo rotacionado em 0º, 90º, 180º e 270º\n",
    "        \n",
    "        Parâmetros\n",
    "        ----------\n",
    "        filename : str\n",
    "            Nome do arquivo, .jpg por exemplo, do alvo\n",
    "            \n",
    "        Retorno\n",
    "        -------\n",
    "        list\n",
    "            Lista contendo o alvo rotacionado em 0º, 90º, 180º e 270º (nessa ordem)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Lendo o alvo, convertendo para escalas de cinza e binarizando\n",
    "    target = cv2.imread(filename)\n",
    "    target = cv2.cvtColor(target, cv2.COLOR_BGR2GRAY)\n",
    "    target[target < 25] = 0\n",
    "    target[target >= 25] = 255\n",
    "    \n",
    "    targets_list = []\n",
    "    \n",
    "    # Rotacionando o alvo em cada um dos ângulos e salvando em uma lista\n",
    "    for angle in [0, 90, 180, 270]:\n",
    "        M = cv2.getRotationMatrix2D((target.shape[1]/2, target.shape[0]/2), angle, 1)\n",
    "        targets_list.append(cv2.warpAffine(target, M, (target.shape[0], target.shape[1])))\n",
    "                            \n",
    "    return targets_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Função similarity_func\n",
    "\n",
    "- Função criada para retornar o quão similar duas imagens são.\n",
    "- Fizemos um cálculo de diferença média absoluta dos pixels para tal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity_func(img1, img2):\n",
    "    \"\"\"\n",
    "        Função de similaridade usando a diferença média dos pixels\n",
    "        \n",
    "        Parâmetros\n",
    "        ----------\n",
    "        img1 : numpy.ndarray\n",
    "            Imagem 1 a ser comparada\n",
    "            \n",
    "        img2 : numpy.ndarray\n",
    "            Imagem 2 a ser comparada\n",
    "            \n",
    "        Retorno\n",
    "        -------\n",
    "            Retorna o valor da diferença média dos pixels\n",
    "    \"\"\"\n",
    "    \n",
    "    return np.sum(np.abs(img1 - img2)) / (img1.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Função template_matching\n",
    "- Essa função cumpre o papel de: para cada imagem do alvo rotacionado, verificar o quão similar ela é com a imagem obtida no passo da homografia. Salvando o índice da imagem que possui o menor valor retornado pela função similarity_func, em outras palavras, a mais similar.\n",
    "- Caso essa imagem não possua valor de similaridade menor do que a tolerância definida, não aceitamos e retornamos -1. Caso contrário, retornamos o índice encontrado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def template_matching(img, targets, sim_func, tol=25):\n",
    "    \"\"\"\n",
    "        Função que realiza o casamento de template\n",
    "        \n",
    "        Parâmetros\n",
    "        ----------\n",
    "        img : numpy.ndarray\n",
    "            Imagem que se quer casar\n",
    "            \n",
    "        targets : numpy.ndarray list\n",
    "            Lista de alvos que iremos casar\n",
    "            \n",
    "        simFunc : function\n",
    "            Função de similaridade que aceita dois numpy.ndarray,\n",
    "            realiza os cálculos e retorna um número\n",
    "            \n",
    "        tol : float, opcional\n",
    "            Tolerância para ser um casamento válido (por padrão é 25)\n",
    "            \n",
    "        Retorno\n",
    "        -------\n",
    "        int\n",
    "            Caso o valor de similaridade esteja abaixo da tolerância,\n",
    "            retornamos o índice do alvo que resultou em um casamento\n",
    "            bem-sucedido (seguindo a mesma ordem dos ângulos).\n",
    "            Senão, retornamos -1.\n",
    "    \"\"\"\n",
    "    \n",
    "    min_similarity = sim_func(img, targets[0])\n",
    "    min_pos = 0\n",
    "    \n",
    "    # Caminhando por cada alvo, comparando o valor de similaridade do atual e \n",
    "    # atualizando, caso necessário, as variáveis\n",
    "    for i in range(1, len(targets)):\n",
    "        current = sim_func(img, targets[i])\n",
    "        if current < min_similarity:\n",
    "            min_similarity = current\n",
    "            min_pos = i\n",
    "    \n",
    "    return min_pos if min_similarity <= tol else -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encontrando os alvos para os 300 primeiros frames\n",
    "\n",
    "- Nessa célula usaremos a findContours para encontrar os alvos.\n",
    "- Aliada a isso, iremos usar as funções de homografia e template_matching implementadas no TP1 para verificar se temos um match válido ou não."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = get_targets('alvo.jpg')\n",
    "selected = []\n",
    "pts = []\n",
    "pos = []\n",
    "for frame in frames[:1].copy():\n",
    "    # Convertendo a imagem para tons de cinza\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_RGB2GRAY)\n",
    "    gray = cv2.bilateralFilter(gray, 11, 17, 17)\n",
    "    \n",
    "    # Detectando bordas com Canny e contornos\n",
    "    canny = cv2.Canny(gray, 100, 200)\n",
    "    contours, _ = cv2.findContours(canny, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    # Guardando uma lista de pontos para os possíveis alvos\n",
    "#     pts = []\n",
    "    \n",
    "    for c in contours:\n",
    "        # Aproximando o contorno via um polígono \n",
    "        peri = cv2.arcLength(c, True)\n",
    "        approx = cv2.approxPolyDP(c, 0.02 * peri, True)\n",
    "        \n",
    "        # Caso esse polígono possua 4 pontos adicionamos ele na nossa lista se a homografia retornar como correto\n",
    "        if len(approx) == 4:\n",
    "            homog = homography(np.float32(gray), np.float32(approx), targets[0])\n",
    "            pos_target = template_matching(homog, targets, similarity_func)\n",
    "            if  pos_target != -1:\n",
    "                pos.append(pos_target)\n",
    "                pts.append(approx)\n",
    "                \n",
    "    # Desenhando os contornos\n",
    "#     for c in pts:\n",
    "#         cv2.drawContours(frame, c, -1, (0,255,0), 5)\n",
    "\n",
    "    cv2.circle(frame, tuple(pts[0][0][0]), 5, (0,255,0), -1)\n",
    "    cv2.circle(frame, tuple(pts[0][1][0]), 5, (255,255,255), -1)\n",
    "    cv2.circle(frame, tuple(pts[0][2][0]), 5, (0,0,0), -1)\n",
    "    cv2.circle(frame, tuple(pts[0][3][0]), 5, (100,100,100), -1)\n",
    "        \n",
    "    selected.append(frame)\n",
    "\n",
    "print(pts)\n",
    "print(pos)\n",
    "show(selected[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exibindo os frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for frame in selected:    \n",
    "    # Exibindo o frame\n",
    "    cv2.imshow('Finding targets', frame)\n",
    "    \n",
    "    # Caso o usuário aperte 'q', o vídeo termina\n",
    "    if cv2.waitKey(24) == ord('q'):\n",
    "        break\n",
    "        \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Renderizando a cena para o primeiro frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Definindo os parâmetros intrínsecos da câmera através da calibração pelo MATLAB\n",
    "cameraParams = {\n",
    "    'fc': [536.19341, 536.14756],\n",
    "    'cc': [317.64968, 233.56773],\n",
    "    'kc': np.array([0.07459, -0.15101, -0.00544, 0.00111, 0.00000])\n",
    "}\n",
    "\n",
    "# Definindo a matriz de parâmetros intrínsecos\n",
    "intMatrix = np.array([\n",
    "    [cameraParams['fc'][0], 0.0, cameraParams['cc'][0]],\n",
    "    [0.0, cameraParams['fc'][1], cameraParams['cc'][1]],\n",
    "    [0.0, 0.0, 1.0]\n",
    "])\n",
    "\n",
    "dst = np.float32([[-1,1,1], [1,1,1], [1,-1,1], [-1,-1,1]])\n",
    "ret, rvec, tvec = cv2.solvePnP(dst, np.float32(pts[0]), intMatrix, cameraParams['kc'])\n",
    "rotm = cv2.Rodrigues(rvec)[0]\n",
    "\n",
    "print('tvec:', tvec)\n",
    "\n",
    "m = np.array([\n",
    "    [rotm[0][0], rotm[0][1], rotm[0][2], tvec[0]],\n",
    "    [rotm[1][0], rotm[1][1], rotm[1][2], -tvec[1]],\n",
    "    [rotm[2][0], rotm[2][1], rotm[2][2], -tvec[2]],\n",
    "    [0.0, 0.0, 0.0, 1.0]\n",
    "])\n",
    "\n",
    "# m = m * np.array([[ 1.0,  1.0,  1.0,  1.0],\n",
    "#                   [-1.0, -1.0, -1.0, -1.0],\n",
    "#                   [-1.0, -1.0, -1.0, -1.0],\n",
    "#                   [ 1.0,  1.0,  1.0,  1.0]])\n",
    "\n",
    "m = np.transpose(m)\n",
    "\n",
    "# Definindo a largura e altura da nossa janela\n",
    "width, height = 640, 480\n",
    "\n",
    "# Definindo a função que desenha o background com textura\n",
    "def showBackground():\n",
    "    glDepthMask(GL_FALSE)\n",
    "    \n",
    "    # Definindo a projeção como ortográfica\n",
    "    glMatrixMode(GL_PROJECTION)\n",
    "    glPushMatrix()\n",
    "    glLoadIdentity()\n",
    "    gluOrtho2D(0, width, 0, height)\n",
    "    \n",
    "    # Habilitando a textura\n",
    "    glEnable(GL_TEXTURE_2D)\n",
    "    glBindTexture(GL_TEXTURE_2D, textureId)\n",
    "    glMatrixMode(GL_MODELVIEW)\n",
    "    glPushMatrix()\n",
    "    # Desenhando um quadrilátero do tamanho da tela com a textura\n",
    "    glBegin(GL_QUADS)\n",
    "    glTexCoord2f(0, 0); glVertex2f(0, 0)\n",
    "    glTexCoord2f(1, 0); glVertex2f(width, 0)\n",
    "    glTexCoord2f(1, 1); glVertex2f(width, height)\n",
    "    glTexCoord2f(0, 1); glVertex2f(0, height)\n",
    "    glEnd()\n",
    "    glPopMatrix()\n",
    "    glMatrixMode(GL_PROJECTION)\n",
    "    glPopMatrix()\n",
    "    glMatrixMode(GL_MODELVIEW)\n",
    "    \n",
    "    # Desabilitando a textura e chamando glFlush\n",
    "    glBindTexture(GL_TEXTURE_2D, 0)\n",
    "    glDepthMask(GL_TRUE)\n",
    "    glFlush()\n",
    "\n",
    "# Definindo a função de desenhar\n",
    "def draw():\n",
    "    # Limpando os buffers\n",
    "    glClear(GL_COLOR_BUFFER_BIT | GL_DEPTH_BUFFER_BIT)\n",
    "    \n",
    "    # Desenhando o fundo\n",
    "    showBackground()\n",
    "    \n",
    "    glMatrixMode(GL_MODELVIEW)\n",
    "    glLoadIdentity()\n",
    "    glPushMatrix()\n",
    "    glLoadMatrixf(m)\n",
    "    glCallList(obj.gl_list)\n",
    "    glPopMatrix()\n",
    "    \n",
    "    # Trocando de buffer para exibir na tela\n",
    "    glutSwapBuffers()\n",
    "    \n",
    "# Iniciando o GLUT\n",
    "glutInit()\n",
    "\n",
    "# Iniciando a posição da janela, dimensões e criando a memsa\n",
    "glutInitWindowPosition(0, 0)\n",
    "glutInitWindowSize(width, height)\n",
    "glutCreateWindow('TP2')\n",
    "\n",
    "# Lendo a textura do fundo\n",
    "textureId = loadBackgroundTexture(frames[0])\n",
    "\n",
    "# Habilitando o uso de texturas\n",
    "glEnable(GL_TEXTURE_2D)\n",
    "\n",
    "glEnable(GL_DEPTH_TEST)\n",
    "\n",
    "obj = OBJ('Pikachu.obj', swapyz=True)\n",
    "\n",
    "glMatrixMode(GL_PROJECTION)\n",
    "glLoadIdentity()\n",
    "fx = cameraParams['fc'][0]\n",
    "fy = cameraParams['fc'][1]\n",
    "fovy = 2 * np.arctan(0.5 * height / fy)*180 / np.pi\n",
    "aspect = (width*fy) / (height*fx)\n",
    "gluPerspective(fovy, aspect, 0.1, 100.0)\n",
    "\n",
    "# Definindo a cor de limpeza do fundo\n",
    "glClearColor(0.2, 0.2, 0.2, 0.0)\n",
    "\n",
    "# Iniciando o loop\n",
    "glutDisplayFunc(draw)\n",
    "# glutIdleFunc(draw)\n",
    "glutMainLoop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Definindo os parâmetros intrínsecos da câmera através da calibração pelo MATLAB\n",
    "# cameraParams = {\n",
    "#     'fc': [536.19341, 536.14756],\n",
    "#     'cc': [317.64968, 233.56773],\n",
    "#     'kc': np.array([0.07459, -0.15101, -0.00544, 0.00111, 0.00000])\n",
    "# }\n",
    "\n",
    "# # Definindo a matriz de parâmetros intrínsecos\n",
    "# intMatrix = np.array([\n",
    "#     [cameraParams['fc'][0], 0.0, cameraParams['cc'][0]],\n",
    "#     [0.0, cameraParams['fc'][1], cameraParams['cc'][1]],\n",
    "#     [0.0, 0.0, 1.0]\n",
    "# ])\n",
    "\n",
    "# ret, rvec, tvec = cv2.solvePnP(np.float32([[0,0,0], [0,310,0], [310,310,0], [310,0,0]]), np.float32(pts[0]), intMatrix, cameraParams['kc'])\n",
    "# rotm = cv2.Rodrigues(rvec)[0]\n",
    "\n",
    "# m = np.array([\n",
    "#     [rotm[0][0], rotm[0][1], rotm[0][2], 0.0],\n",
    "#     [rotm[1][0], rotm[1][1], rotm[1][2], 0.0],\n",
    "#     [rotm[2][0], rotm[2][1], rotm[2][2], 0.0],\n",
    "#     [0.0, 0.0, 0.0, 1.0]\n",
    "# ])\n",
    "\n",
    "# m = m * np.array([[ 1.0,  1.0,  1.0,  1.0],\n",
    "#                   [-1.0, -1.0, -1.0, -1.0],\n",
    "#                   [-1.0, -1.0, -1.0, -1.0],\n",
    "#                   [ 1.0,  1.0,  1.0,  1.0]])\n",
    "\n",
    "# m = np.transpose(m)\n",
    "\n",
    "# # Definindo a largura e altura da nossa janela\n",
    "# width, height = 640, 480\n",
    "\n",
    "# if not glfw.init():\n",
    "#     print('*** OPS ***')\n",
    "    \n",
    "# window = glfw.create_window(640, 480, 'TESTE', None, None)\n",
    "# glfw.make_context_current(window)\n",
    "\n",
    "# fx = cameraParams['fc'][0]\n",
    "# fy = cameraParams['fc'][1]\n",
    "# fovy = 2 * np.arctan(0.5 * height / fy)*180 / np.pi\n",
    "# aspect = (width*fy) / (height*fx)\n",
    "# gluPerspective(fovy, aspect, 0.1, 100.0)\n",
    "\n",
    "# obj = OBJ('Pikachu.obj', swapyz=True)\n",
    "\n",
    "# glClearColor(0.2, 0.2, 0.2, 0.0)\n",
    "\n",
    "# while not glfw.window_should_close(window):\n",
    "#     glfw.poll_events()\n",
    "    \n",
    "#     # Limpando os buffers\n",
    "#     glClear(GL_COLOR_BUFFER_BIT | GL_DEPTH_BUFFER_BIT)\n",
    "    \n",
    "#     # Desenhando o fundo\n",
    "# #     showBackground()\n",
    "    \n",
    "#     glMatrixMode(GL_MODELVIEW)\n",
    "#     glLoadIdentity()\n",
    "#     glPushMatrix()\n",
    "#     glLoadMatrixd(m)\n",
    "#     glCallList(obj.gl_list)\n",
    "#     glPopMatrix()\n",
    "    \n",
    "#     glfw.swap_buffers(window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
